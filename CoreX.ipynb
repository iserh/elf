{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5746a0fb",
   "metadata": {},
   "source": [
    "# Anchored CoreX on STS Benchmark dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c6787f",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24381b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from corextopic import corextopic as ct\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sentence_similarity.data import Pipeline, PipelineConfig, STSBenchmark\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "assert data_dir.exists(), \"data_dir does not exist.\"\n",
    "output_dir = Path(\"data\")\n",
    "output_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f4a63",
   "metadata": {},
   "source": [
    "## Preprocessing & Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be053e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PipelineConfig(\n",
    "    filtered_pos_tags=[],\n",
    "    remove_stop_words=True,\n",
    "    remove_numbers=False,\n",
    "    remove_symbols=False,\n",
    "    remove_punctuation=False,\n",
    ")\n",
    "pipeline = Pipeline(config)\n",
    "config.save(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c403ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "sts_benchmark = STSBenchmark(data_dir, partition=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ffeeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 5552/5552 [00:03<00:00, 1540.68it/s]\n",
      "Preprocessing: 100%|██████████| 5552/5552 [00:02<00:00, 1915.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocess sentences\n",
    "s1_preprocessed = pipeline(sts_benchmark.s1)\n",
    "s2_preprocessed = pipeline(sts_benchmark.s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "740d03a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>plane take .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>man play large flute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>man spread shred cheese pizza.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>man play chess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>man play cello.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>Palestinian hunger striker, Israel reach deal</td>\n",
       "      <td>palestinian hunger striker, Israel reach deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>Assad says Syria will comply with UN arms reso...</td>\n",
       "      <td>Assad say Syria comply UN arm resolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>South Korean President Sorry For Ferry Response</td>\n",
       "      <td>south korean President sorry Ferry Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>Food price hikes raise concerns in Iran</td>\n",
       "      <td>food price hike raise concern Iran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>Obama made last-minute decision on Syria approval</td>\n",
       "      <td>Obama -minute decision Syria approval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5552 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     s1  \\\n",
       "0                                A plane is taking off.   \n",
       "1                       A man is playing a large flute.   \n",
       "2         A man is spreading shreded cheese on a pizza.   \n",
       "3                          Three men are playing chess.   \n",
       "4                           A man is playing the cello.   \n",
       "...                                                 ...   \n",
       "5547      Palestinian hunger striker, Israel reach deal   \n",
       "5548  Assad says Syria will comply with UN arms reso...   \n",
       "5549    South Korean President Sorry For Ferry Response   \n",
       "5550            Food price hikes raise concerns in Iran   \n",
       "5551  Obama made last-minute decision on Syria approval   \n",
       "\n",
       "                                                  0  \n",
       "0                                      plane take .  \n",
       "1                             man play large flute.  \n",
       "2                    man spread shred cheese pizza.  \n",
       "3                                   man play chess.  \n",
       "4                                   man play cello.  \n",
       "...                                             ...  \n",
       "5547  palestinian hunger striker, Israel reach deal  \n",
       "5548       Assad say Syria comply UN arm resolution  \n",
       "5549    south korean President sorry Ferry Response  \n",
       "5550             food price hike raise concern Iran  \n",
       "5551          Obama -minute decision Syria approval  \n",
       "\n",
       "[5552 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([sts_benchmark.s1, s1_preprocessed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f20e8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11104, 9393)\n",
      "# digits: 360\n"
     ]
    }
   ],
   "source": [
    "# fit TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(strip_accents=\"ascii\", binary=True, ngram_range=(1,1))\n",
    "doc_word = vectorizer.fit_transform(pd.concat([s1_preprocessed, s2_preprocessed]))\n",
    "doc_word = ss.csr_matrix(doc_word)\n",
    "\n",
    "# save vectorizer\n",
    "with open(output_dir / \"vectorizer.bin\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "print(doc_word.shape)  # n_docs x m_words\n",
    "\n",
    "# Get words that label the columns (needed to extract readable topics and make anchoring easier)\n",
    "words = list(np.asarray(vectorizer.get_feature_names_out()))\n",
    "print(\"# digits:\", len([word for word in words if word.isdigit()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007371cf",
   "metadata": {},
   "source": [
    "## CoreX Topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b324b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CorEx topic model with 50 topics\n",
    "topic_model = ct.Corex(n_hidden=50, words=words, max_iter=300)\n",
    "topic_model.fit(doc_word, words=words)\n",
    "\n",
    "plt.plot(topic_model.tc_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95749f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(output_dir / \"corex_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9323c8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: man, play, woman, dog, guitar, white, black, ride, run, slice\n",
      "1: stock, percent, index, share, cent, nasdaq, composite, point, trading, close\n",
      "2: dow, jones, average, industrial, credit, dji, outfielder, hate, ninth, extradition\n",
      "3: vessel, fill, wonder, jury, nullification, total, bell, microsoft, monteith, cory\n",
      "4: san, suu, kyi, illness, proud, liberty, aung, richard, schedule, plutonium\n",
      "5: usd, yuan, magnitude, quake, strengthen, usgs, weaken, hurricane, cenc, jolt\n",
      "6: ratify, amend, aviv, tel, asylum, universe, explanation, existence, withdraw, moscow\n",
      "7: criticism, king, whitey, ernst, ii, albert, wrongdoing, einstein, bulgergirlfriend, hunt\n",
      "8: decker, double, bus, drive, hood, wheel, ferris, druce, fucking, volt\n",
      "9: requirement, corn, guess, hi, atlantic, doping, absolutely, pacific, terral, actually\n",
      "10: caucus, statue, lenin, topple, murdoch, majority, minimum, santorum, maine, kiev\n",
      "11: plead, guilty, torch, ahmadinejad, temple, steer, jetblue, iranparliament, appearance, buddhist\n",
      "12: exist, fine, enema, karate, leprechaun, fairy, satyrs, oblivion, nirvana, breathe\n",
      "13: mouse, peck, evil, rooster, chicken, snake, less, dangle, oceanshore, skullcap\n",
      "14: ha, margaret, thatcher, 87, ah, lakers, mike, manshoulder, garland, ambo\n",
      "15: sovereign, packet, repeat, ketchup, warship, egyptmain, profile, dutchy, ignore, doom\n",
      "16: notice, nonsensical, extremely, brandeis, heartrending, mood, priority, fantasise, demented, 621\n",
      "17: recuse, carlson, junta, ingo, kober, commerce, videotron, mandelafuneral, selfie, liberiacountryside\n",
      "18: beckham, retire, worldstrict, vietnamdrug, taxi, gorgich, pashtoon, football, stud, urban\n",
      "19: iron, jetpack, dome, spark, intercept, hawaii, beersheba, 239, mutharikadeath, ouster\n",
      "20: unaccptable, bienging, anybody, giva, trashcan, int, gunboat, fisherman, mas, noroviru\n",
      "21: peacekeeper, nigel, farage, reyes, raul, abyei, sudandarfur, santos, discover, imam\n",
      "22: timor, gusmao, consolidate, malian, gao, arts, schools, pave, poisoned, quantity\n",
      "23: hummingbird, kidney, dusty, momentum, dealer, closeup, flying, eurodownward, currencydownward, murders\n",
      "24: wash, freezer, rotor, banner, 144, obliteration, oceanfront, olaf, ona, outsource\n",
      "25: worldold, 116, malevolent, kimura, jiroemon, verify, parade, parallel, particular, plant\n",
      "26: ignorant, willfully, lol, lingus, malituareg, marx, morsisupporter, offences, pickup, pratt\n",
      "27: stab, passersby, promenade, alp, orphan, suffolk, 118, motives, nora, obamas\n",
      "28: 1540, paranoid, photojournalist, pp, preferably, prisoners, resettle, sanchez, sec, organizer\n",
      "29: befriend, modi, taunter, mom, upset, narendra, matchup, mirjaveh, newspaper, obviously\n",
      "30: diplomat, expel, prague, kerrywife, rapid, munich, skeptic, russiasouth, reignite, kosovan\n",
      "31: liar, confusion, braindead, split, metric, mitchell, mko, mod, neglect, obamasupreme\n",
      "32: slanted, blog, catholics, assemble, kurd, laying, liquid, motion, motors, multiple\n",
      "33: abstain, trimester, syriaassad, sunflower, splinter, short, sampson, rockingham, regimeouster, pullback\n",
      "34: definition, soul, hotline, remaining, mubarakpm, orders, oscepresidency, ozawa, pakista, pointed\n",
      "35: koichiro, gemba, lone, master, meal, midnight, mistakenly, morse, movie, lesson\n",
      "36: reconciliation, implication, undermining, grameen, 668, unclear, strikes, square, rowhani, rand\n",
      "37: shithole, haiti, abbott, trapped, surprisingly, stansted, squad, somaliashebab, running, rucker\n",
      "38: 1982, ordeal, orgy, owl, paralyze, pervasive, pricing, networkchokepoint, proportion, reveller\n",
      "39: moloch, scene, 10b, kutte, madrid, mainlandguangdong, mutiny, overshadow, parking, presidentdeath\n",
      "40: foxe, basin, 25pc, skewed, redskins, processor, precondition, password, nationoil, naif\n",
      "41: egyptbrotherhood, beleaguered, accurate, take, skeptical, showbusiness, noticeably, nm, material, leeds\n",
      "42: 119, papacy, patience, pledges, psychiatristcare, rba, recording, retrieve, outer, sacking\n",
      "43: article, tactic, sensor, salafi, sa, renegotiate, refusal, raffles, polarise, poh\n",
      "44: 573, unsuccessful, trigger, tight, thames, struggle, reyna, ref, port, policeman\n",
      "45: adly, imcloneoriginal, insight, kimball, knock, lecture, marsh, mattei, mitzna, pair\n",
      "46: 122, unofficial, tottenham, sweeney, releases, model, minimize, mil, messianic, mesa\n",
      "47: 25bn, incorporate, interestsao, iraqkirkuk, kweifiya, mainstream, missions, newsmagazine, idea, noneconomic\n",
      "48: tie, shoe, noose, 460, millions, napolitano, newsnight, obesity, oge, paralympic\n",
      "49: 165, ukraineaos, teenager, spa, size, shawal, sequent, senateeffort, prelateprivate, perforate\n"
     ]
    }
   ],
   "source": [
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ', '.join(topic_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
