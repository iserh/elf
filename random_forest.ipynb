{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d936036",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae80a0-5b64-4fdc-a194-01b12a52297f",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5bba398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from utils import (CoreXProbsFactory, LDAProbs, SyntaxFactory, preprocess,\n",
    "                   tokenize)\n",
    "\n",
    "data_dir = Path(\".\")\n",
    "model_dir = Path(\"/home/iailab36/iser/models\")\n",
    "\n",
    "SEED = 1337\n",
    "COREX_HIDDEN = 64\n",
    "VEC_FEAT = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3639de72-d37d-43a6-a3b9-b0dd80c8e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load benchmark dataset\n",
    "train_data = pd.read_feather(data_dir / \"stsbenchmark\" / \"sts-train-sbert.feather\")\n",
    "val_data = pd.read_feather(data_dir / \"stsbenchmark\" / \"sts-dev-sbert.feather\")\n",
    "test_data = pd.read_feather(data_dir / \"stsbenchmark\" / \"sts-test.feather\")\n",
    "\n",
    "train_data = pd.concat([train_data, val_data]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f11c5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = lambda SEED: RandomForestRegressor(criterion=\"squared_error\", n_estimators=100, random_state=SEED)\n",
    "decision_tree = lambda SEED: DecisionTreeRegressor(random_state=SEED, max_depth=5)\n",
    "mlp = lambda SEED: MLPRegressor((512, 256), random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932b988-63fc-4b0d-9da6-7b1f28009044",
   "metadata": {},
   "source": [
    "## Pre-compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd268a3-0bc4-4346-82c3-af4fc9786a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = []\n",
    "features_val = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d9631-bda1-404d-82b6-de3cea1ea494",
   "metadata": {},
   "source": [
    "### topic model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593b88dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topic_probs = CoreXProbsFactory(\n",
    "    vectorizer_path=model_dir / f\"sts_vec={VEC_FEAT}\",\n",
    "    corex_name=f\"corex_n_hidden={COREX_HIDDEN}_iter=7\",\n",
    ")\n",
    "\n",
    "# get_topic_probs = LDAProbs(model_dir / f\"sts_lda_hidden={COREX_HIDDEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8023d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute topic probabilities\n",
    "topic_probs_train_1 = get_topic_probs(train_data.s1)\n",
    "topic_probs_train_2 = get_topic_probs(train_data.s2)\n",
    "topic_probs_test_1 = get_topic_probs(test_data.s1)\n",
    "topic_probs_test_2 = get_topic_probs(test_data.s2)\n",
    "# concatenate topics of the two sentences\n",
    "topic_probs_train = np.concatenate([topic_probs_train_1, topic_probs_train_2], axis=1)\n",
    "topic_probs_test = np.concatenate([topic_probs_test_1, topic_probs_test_2], axis=1)\n",
    "# add to features list\n",
    "features_train.append(topic_probs_train)\n",
    "features_val.append(topic_probs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5e1bd-6f65-416a-ae66-d30480beb0ac",
   "metadata": {},
   "source": [
    "### syntax features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ea3583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_syntax_deps = SyntaxFactory()\n",
    "# # compute syntax tokens\n",
    "# syntax_train_1 = get_syntax_deps(train_data.s1)\n",
    "# syntax_train_2 = get_syntax_deps(train_data.s2)\n",
    "# syntax_test_1 = get_syntax_deps(test_data.s1)\n",
    "# syntax_test_2 = get_syntax_deps(test_data.s2)\n",
    "# # mask matching syntax\n",
    "# syntax_train = (syntax_train_1 == syntax_train_2).astype(int)\n",
    "# syntax_test = (syntax_test_1 == syntax_test_2).astype(int)\n",
    "# # append to features list\n",
    "# features_train.append(syntax_train)\n",
    "# features_val.append(syntax_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb0237",
   "metadata": {},
   "source": [
    "## Training without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c54bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (7030, 128)\n"
     ]
    }
   ],
   "source": [
    "# create input vectors\n",
    "X_train = np.concatenate(features_train, axis=1)\n",
    "X_test = np.concatenate(features_val, axis=1)\n",
    "# create targets\n",
    "y_train = train_data.score\n",
    "y_test = test_data.score\n",
    "print(\"X_train:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "539bac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanRank-train: 0.9807,\t SpearmanRank-test: 0.5302\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "perm = np.random.permutation(X_train.shape[0])\n",
    "X_train_ = X_train[perm]\n",
    "y_train_ = y_train[perm]\n",
    "\n",
    "model = random_forest(SEED)\n",
    "model.fit(X_train_, y_train_)\n",
    "\n",
    "# evaluate model\n",
    "spearman_train = spearmanr(model.predict(X_train), y_train)[0]\n",
    "spearman_test = spearmanr(model.predict(X_test), y_test)[0]\n",
    "\n",
    "print(f\"SpearmanRank-train: {spearman_train:.4f},\\t SpearmanRank-test: {spearman_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b30fd-3063-4941-9b5c-8ba14e948361",
   "metadata": {},
   "source": [
    "## Training with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4605f626-fdda-4253-81aa-e58530d6c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load augmentation dataset\n",
    "aug_data = pd.read_feather(data_dir / \"stsbenchmark\" / \"df_augment.feather\")\n",
    "\n",
    "features_aug = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc96d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get topics of the augmented sentences\n",
    "topic_probs_augmented = np.concatenate([\n",
    "    topic_probs_train_1[aug_data.idx1],\n",
    "    topic_probs_train_2[aug_data.idx2]\n",
    "], axis=1)\n",
    "features_aug.append(topic_probs_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aef96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # syntax features\n",
    "# syntax_aug = (syntax_train_1[aug_data.idx1] == syntax_train_2[aug_data.idx2]).astype(int)\n",
    "# features_aug.append(syntax_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f11a8e5-2a08-4886-9839-72c29bb8d5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#augmented: 1634\n",
      "#(train+augmented): 8664\n"
     ]
    }
   ],
   "source": [
    "# create inputs / targets of augmented dataset\n",
    "X_aug = np.concatenate(features_aug, axis=1)\n",
    "y_aug = aug_data.score\n",
    "print(f\"#augmented: {y_aug.shape[0]}\")\n",
    "\n",
    "X_train_w_aug = np.concatenate([X_train, X_aug])\n",
    "y_train_w_aug = np.concatenate([y_train, y_aug])\n",
    "print(f\"#(train+augmented): {y_train_w_aug.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb5a2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(SEED)\n",
    "# perm = np.random.permutation(X_train_w_aug.shape[0])\n",
    "# X_train_w_aug_ = X_train_w_aug[perm]\n",
    "# y_train_w_aug_ = y_train_w_aug[perm]\n",
    "\n",
    "# model = random_forest(SEED)\n",
    "# model.fit(X_train_w_aug_, y_train_w_aug_)\n",
    "\n",
    "# # evaluate model\n",
    "# spearman_train = spearmanr(model.predict(X_train), y_train)[0]\n",
    "# spearman_test = spearmanr(model.predict(X_test), y_test)[0]\n",
    "\n",
    "# print(f\"SpearmanRank-train: {spearman_train:.4f},\\t SpearmanRank-test: {spearman_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a683639f",
   "metadata": {},
   "source": [
    "## Qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca992f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unit vectors\n",
    "# x1 = topic_probs_train_1 / np.linalg.norm(topic_probs_train_1, axis=1)[:, None]\n",
    "# x2 = topic_probs_train_2 / np.linalg.norm(topic_probs_train_2, axis=1)[:, None]\n",
    "\n",
    "# y_naiv = (x1[:, None, ...] @ x2[..., None]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d748176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import wasserstein_distance\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # softmax\n",
    "# x1 = np.exp(topic_probs_train_1)/np.exp(topic_probs_train_1).sum(0)\n",
    "# x2 = np.exp(topic_probs_train_2)/np.exp(topic_probs_train_2).sum(0)\n",
    "\n",
    "# dists = np.array([wasserstein_distance(x1[i], x2[i]) for i in range(x1.shape[0])])\n",
    "\n",
    "# mms = MinMaxScaler()\n",
    "# y_naiv = mms.fit_transform(dists.reshape(-1, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "958fe9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_1 = test_data.s1.apply(tokenize)\n",
    "processed_2 = test_data.s2.apply(tokenize)\n",
    "\n",
    "y_naiv = np.array([\n",
    "    np.array([token in tokens2 for token in tokens1], dtype=float).sum() / max(len(tokens1), len(tokens2))\n",
    "    for tokens1, tokens2 in zip(processed_1, processed_2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d610117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanRank-val: 0.6387\n"
     ]
    }
   ],
   "source": [
    "spearman_val = spearmanr(y_naiv, y_test)[0]\n",
    "print(f\"SpearmanRank-val: {spearman_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "660a9818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanRank-val: 0.5302\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "spearman_val = spearmanr(y_pred, y_test)[0]\n",
    "print(f\"SpearmanRank-val: {spearman_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db264611-0f48-4b8b-978c-9c1b637472c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_data[[\"s1\", \"s2\"]].copy()\n",
    "df[\"s1_processed\"] = df.s1.apply(preprocess)\n",
    "df[\"s2_processed\"] = df.s2.apply(preprocess)\n",
    "df[\"y_true\"] = y_test\n",
    "df[\"y_pred\"] = y_pred\n",
    "df[\"y_naiv\"] = y_naiv\n",
    "# df[[\"root\", \"nsubj\", \"dobj\"]] = [pd.Series(s) for s in syntax_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35b681c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s1_processed</th>\n",
       "      <th>s2_processed</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_naiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A woman is dancing in the rain.</td>\n",
       "      <td>A woman dances in the rain out side.</td>\n",
       "      <td>woman danc rain .</td>\n",
       "      <td>woman danc rain side .</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.545929</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>A train is moving.</td>\n",
       "      <td>A man is doing yoga.</td>\n",
       "      <td>train move .</td>\n",
       "      <td>man yoga .</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.482292</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>A man is holding a leaf.</td>\n",
       "      <td>A monkey is fighting a man.</td>\n",
       "      <td>man hold leaf .</td>\n",
       "      <td>monkey fight man .</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.482234</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>A woman is peeling shrimp.</td>\n",
       "      <td>A man is squeezing water.</td>\n",
       "      <td>woman peel shrimp .</td>\n",
       "      <td>man squeez water .</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.541840</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>A woman opens a window.</td>\n",
       "      <td>A man is crawling.</td>\n",
       "      <td>woman open window .</td>\n",
       "      <td>man crawl .</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.488378</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>5 nations meet on haze</td>\n",
       "      <td>Putin's marriage at an end</td>\n",
       "      <td>num nation meet haze</td>\n",
       "      <td>putin marriag end</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.470302</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Prominent AIDS researchers killed in Malaysian...</td>\n",
       "      <td>Top AIDS Researcher Killed in Malaysia Plane C...</td>\n",
       "      <td>promin aid research kill malaysian plane crash</td>\n",
       "      <td>top aid research kill malaysia plane crash</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.478477</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>Protests continue in tense Ukraine capital</td>\n",
       "      <td>Protests Continue In Ukraine's Capital</td>\n",
       "      <td>protest continu tens ukrain capit</td>\n",
       "      <td>protest continu ukrain capit</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.535061</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>3 dead, 4 missing in central China constructio...</td>\n",
       "      <td>One dead, 8 missing in Vietnam boat accident</td>\n",
       "      <td>num dead , num miss central china construct accid</td>\n",
       "      <td>one dead , num miss vietnam boat accid</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.596987</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>World Cup live: France 0-0 Germany</td>\n",
       "      <td>World Cup live: Germany 0-0 Ghana</td>\n",
       "      <td>world cup live : franc num germani</td>\n",
       "      <td>world cup live : germani num ghana</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.719533</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     s1  \\\n",
       "38                      A woman is dancing in the rain.   \n",
       "61                                   A train is moving.   \n",
       "65                             A man is holding a leaf.   \n",
       "66                           A woman is peeling shrimp.   \n",
       "72                              A woman opens a window.   \n",
       "...                                                 ...   \n",
       "1065                             5 nations meet on haze   \n",
       "1072  Prominent AIDS researchers killed in Malaysian...   \n",
       "1075         Protests continue in tense Ukraine capital   \n",
       "1089  3 dead, 4 missing in central China constructio...   \n",
       "1091                 World Cup live: France 0-0 Germany   \n",
       "\n",
       "                                                     s2  \\\n",
       "38                 A woman dances in the rain out side.   \n",
       "61                                 A man is doing yoga.   \n",
       "65                          A monkey is fighting a man.   \n",
       "66                            A man is squeezing water.   \n",
       "72                                   A man is crawling.   \n",
       "...                                                 ...   \n",
       "1065                         Putin's marriage at an end   \n",
       "1072  Top AIDS Researcher Killed in Malaysia Plane C...   \n",
       "1075             Protests Continue In Ukraine's Capital   \n",
       "1089       One dead, 8 missing in Vietnam boat accident   \n",
       "1091                  World Cup live: Germany 0-0 Ghana   \n",
       "\n",
       "                                           s1_processed  \\\n",
       "38                                    woman danc rain .   \n",
       "61                                         train move .   \n",
       "65                                      man hold leaf .   \n",
       "66                                  woman peel shrimp .   \n",
       "72                                  woman open window .   \n",
       "...                                                 ...   \n",
       "1065                               num nation meet haze   \n",
       "1072     promin aid research kill malaysian plane crash   \n",
       "1075                  protest continu tens ukrain capit   \n",
       "1089  num dead , num miss central china construct accid   \n",
       "1091                 world cup live : franc num germani   \n",
       "\n",
       "                                    s2_processed  y_true    y_pred    y_naiv  \n",
       "38                        woman danc rain side .    1.00  0.545929  0.800000  \n",
       "61                                    man yoga .    0.00  0.482292  0.333333  \n",
       "65                            monkey fight man .    0.00  0.482234  0.500000  \n",
       "66                            man squeez water .    0.04  0.541840  0.250000  \n",
       "72                                   man crawl .    0.00  0.488378  0.250000  \n",
       "...                                          ...     ...       ...       ...  \n",
       "1065                           putin marriag end    0.00  0.470302  0.000000  \n",
       "1072  top aid research kill malaysia plane crash    1.00  0.478477  0.714286  \n",
       "1075                protest continu ukrain capit    1.00  0.535061  0.800000  \n",
       "1089      one dead , num miss vietnam boat accid    0.08  0.596987  0.666667  \n",
       "1091          world cup live : germani num ghana    0.28  0.719533  0.857143  \n",
       "\n",
       "[144 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.y_true - df.y_pred).abs() > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c79e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"ad\" in get_topic_probs.vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e543c6b",
   "metadata": {},
   "source": [
    "### Naive cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_lg\", exclude=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25653d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"tok2vec\"] = df[[\"s1\", \"s2\"]].apply(lambda row: nlp(row.s1).similarity(nlp(row.s2)), axis=1)\n",
    "# print(f\"SpearmanRank-val: {spearmanr(df.tok2vec, df.y_true)[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = nlp(\"Blue and red plane in mid-air flight.\")\n",
    "# print(\"\\t\".join([token.dep_ for token in doc]))\n",
    "# print(\"\\t\".join([token.lemma_ for token in doc]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2031cad5f309ecce3c7725635a5b7ce703908d09c65dbfde6df395d8b1d2cb2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
