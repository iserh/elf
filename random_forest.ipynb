{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d936036",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae80a0-5b64-4fdc-a194-01b12a52297f",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5bba398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"/home/iailab36/iser/data\")\n",
    "model_dir = Path(\"/home/iailab36/iser/models\")\n",
    "\n",
    "SEEDS = [1337, 42, 87]\n",
    "COREX_HIDDEN = 64\n",
    "VEC_FEAT = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3639de72-d37d-43a6-a3b9-b0dd80c8e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load benchmark dataset\n",
    "train_data = pd.read_feather(data_dir / \"stsbenchmark\" / \"sts-train.feather\")\n",
    "val_data = pd.read_feather(data_dir / \"stsbenchmark\" / \"sts-dev.feather\")\n",
    "test_data = pd.read_feather(data_dir / \"stsbenchmark\" / \"sts-test.feather\")\n",
    "\n",
    "train_data = pd.concat([train_data, val_data]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932b988-63fc-4b0d-9da6-7b1f28009044",
   "metadata": {},
   "source": [
    "## Pre-compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd268a3-0bc4-4346-82c3-af4fc9786a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iai/user/iser/.conda/envs/main/lib/python3.9/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from utils import CoreXProbsFactory, SyntaxFactory\n",
    "\n",
    "features_train = []\n",
    "features_val = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d9631-bda1-404d-82b6-de3cea1ea494",
   "metadata": {},
   "source": [
    "### topic model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593b88dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topic_probs = CoreXProbsFactory(\n",
    "    vectorizer_path=model_dir / f\"sts_vec={VEC_FEAT}\",\n",
    "    corex_name=f\"corex_n_hidden={COREX_HIDDEN}_iter=7\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8023d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute topic probabilities\n",
    "topic_probs_train_1 = get_topic_probs(train_data.s1)\n",
    "topic_probs_train_2 = get_topic_probs(train_data.s2)\n",
    "topic_probs_test_1 = get_topic_probs(test_data.s1)\n",
    "topic_probs_test_2 = get_topic_probs(test_data.s2)\n",
    "# concatenate topics of the two sentences\n",
    "topic_probs_train = np.concatenate([topic_probs_train_1, topic_probs_train_2], axis=1)\n",
    "topic_probs_test = np.concatenate([topic_probs_test_1, topic_probs_test_2], axis=1)\n",
    "# add to features list\n",
    "features_train.append(topic_probs_train)\n",
    "features_val.append(topic_probs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5e1bd-6f65-416a-ae66-d30480beb0ac",
   "metadata": {},
   "source": [
    "### syntax features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea3583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_syntax_deps = SyntaxFactory()\n",
    "# compute syntax tokens\n",
    "syntax_train_1 = get_syntax_deps(train_data.s1)\n",
    "syntax_train_2 = get_syntax_deps(train_data.s2)\n",
    "syntax_test_1 = get_syntax_deps(test_data.s1)\n",
    "syntax_test_2 = get_syntax_deps(test_data.s2)\n",
    "# mask matching syntax\n",
    "syntax_train = (syntax_train_1 == syntax_train_2).astype(int)\n",
    "syntax_test = (syntax_test_1 == syntax_test_2).astype(int)\n",
    "# append to features list\n",
    "features_train.append(syntax_train)\n",
    "features_val.append(syntax_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb0237",
   "metadata": {},
   "source": [
    "## Training without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c54bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (7030, 131)\n"
     ]
    }
   ],
   "source": [
    "# create input vectors\n",
    "X_train = np.concatenate(features_train, axis=1)\n",
    "X_test = np.concatenate(features_val, axis=1)\n",
    "# create targets\n",
    "y_train = train_data.score\n",
    "y_val = test_data.score\n",
    "print(\"X_train:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f8c0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "train configuration: COREX_HIDDEN=64, VEC_FEAT=10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print()\n",
    "print(f\"train configuration: COREX_HIDDEN={COREX_HIDDEN}, VEC_FEAT={VEC_FEAT}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6017108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without augmentation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"without augmentation\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "539bac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor\n",
      "SpearmanRank-train: 0.9997,\t SpearmanRank-test: 0.2726\n",
      "SpearmanRank-train: 0.9997,\t SpearmanRank-test: 0.2859\n",
      "SpearmanRank-train: 0.9997,\t SpearmanRank-test: 0.2795\n",
      "Mean & Std for <class 'sklearn.tree._classes.DecisionTreeRegressor'>\n",
      "SpearmanRank-train: mean=0.9997, std=0.0000\n",
      "SpearmanRank-test: mean=0.2793, std=0.0054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "spearman_train = np.empty((len(SEEDS,)))\n",
    "spearman_test = np.empty((len(SEEDS,)))\n",
    "\n",
    "rnd_forest = lambda seed: RandomForestRegressor(criterion=\"squared_error\", n_estimators=100, random_state=seed)\n",
    "dec_tree = lambda seed: DecisionTreeRegressor(random_state=seed)\n",
    "mlp = lambda seed: MLPRegressor((512, 256, 128), random_state=seed)\n",
    "\n",
    "for model_cls in [dec_tree]:\n",
    "    print(model_cls(0).__class__.__name__)\n",
    "\n",
    "    for i, seed in enumerate(SEEDS):\n",
    "\n",
    "        model = model_cls(seed)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # evaluate model\n",
    "        spearman_train[i] = spearmanr(model.predict(X_train), y_train)[0]\n",
    "        spearman_test[i] = spearmanr(model.predict(X_test), y_val)[0]\n",
    "\n",
    "        print(f\"SpearmanRank-train: {spearman_train[i]:.4f},\\t SpearmanRank-test: {spearman_test[i]:.4f}\")\n",
    "    \n",
    "    print(f\"Mean & Std for {model.__class__.__name__}\")\n",
    "    print(f\"SpearmanRank-train: mean={spearman_train.mean():.4f}, std={spearman_train.std():.4f}\")\n",
    "    print(f\"SpearmanRank-test: mean={spearman_test.mean():.4f}, std={spearman_test.std():.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b30fd-3063-4941-9b5c-8ba14e948361",
   "metadata": {},
   "source": [
    "## Training with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a69a1270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with augmentation\n"
     ]
    }
   ],
   "source": [
    "print(\"with augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4605f626-fdda-4253-81aa-e58530d6c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load augmentation dataset\n",
    "aug_data = pd.read_feather(\"df_augment.feather\")\n",
    "\n",
    "features_aug = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc96d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get topics of the augmented sentences\n",
    "topic_probs_augmented = np.concatenate([\n",
    "    topic_probs_train_1[aug_data.idx1],\n",
    "    topic_probs_train_2[aug_data.idx2]\n",
    "], axis=1)\n",
    "features_aug.append(topic_probs_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aef96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntax features\n",
    "syntax_aug = (syntax_train_1[aug_data.idx1] == syntax_train_2[aug_data.idx2]).astype(int)\n",
    "features_aug.append(syntax_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f11a8e5-2a08-4886-9839-72c29bb8d5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#augmented: 6307\n",
      "#(train+augmented): 6307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create inputs / targets of augmented dataset\n",
    "X_aug = np.concatenate(features_aug, axis=1)\n",
    "y_aug = aug_data.score\n",
    "print(f\"#augmented: {y_aug.shape[0]}\")\n",
    "\n",
    "X_train_w_aug = np.concatenate([X_train, X_aug])\n",
    "y_train_w_aug = np.concatenate([y_train, y_aug])\n",
    "print(f\"#(train+augmented): {y_aug.shape[0]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "090560af-8f6b-4a62-9439-639897783d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor\n",
      "SpearmanRank-train: 0.9946,\t SpearmanRank-test: 0.2482\n",
      "SpearmanRank-train: 0.9946,\t SpearmanRank-test: 0.2385\n",
      "SpearmanRank-train: 0.9946,\t SpearmanRank-test: 0.2393\n",
      "Mean & Std for DecisionTreeRegressor\n",
      "SpearmanRank-train: mean=0.9946, std=0.0000\n",
      "SpearmanRank-test: mean=0.2420, std=0.0044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spearman_train = np.empty((len(SEEDS,)))\n",
    "spearman_test = np.empty((len(SEEDS,)))\n",
    "\n",
    "for model_cls in [dec_tree]:\n",
    "    print(model_cls(0).__class__.__name__)\n",
    "\n",
    "    for i, seed in enumerate(SEEDS):\n",
    "\n",
    "        model = model_cls(seed)\n",
    "        model.fit(X_train_w_aug, y_train_w_aug)\n",
    "\n",
    "        # evaluate model\n",
    "        spearman_train[i] = spearmanr(model.predict(X_train), y_train)[0]\n",
    "        spearman_test[i] = spearmanr(model.predict(X_test), y_val)[0]\n",
    "\n",
    "        print(f\"SpearmanRank-train: {spearman_train[i]:.4f},\\t SpearmanRank-test: {spearman_test[i]:.4f}\")\n",
    "    \n",
    "    print(f\"Mean & Std for {model.__class__.__name__}\")\n",
    "    print(f\"SpearmanRank-train: mean={spearman_train.mean():.4f}, std={spearman_train.std():.4f}\")\n",
    "    print(f\"SpearmanRank-test: mean={spearman_test.mean():.4f}, std={spearman_test.std():.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a683639f",
   "metadata": {},
   "source": [
    "## Qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca992f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit vectors\n",
    "x1 = topic_probs_train_1 / np.linalg.norm(topic_probs_train_1, axis=1)[:, None]\n",
    "x2 = topic_probs_train_2 / np.linalg.norm(topic_probs_train_2, axis=1)[:, None]\n",
    "\n",
    "y_naiv = (x1[:, None, ...] @ x2[..., None]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# softmax\n",
    "x1 = np.exp(topic_probs_train_1)/np.exp(topic_probs_train_1).sum(0)\n",
    "x2 = np.exp(topic_probs_train_2)/np.exp(topic_probs_train_2).sum(0)\n",
    "\n",
    "dists = np.array([wasserstein_distance(x1[i], x2[i]) for i in range(x1.shape[0])])\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "y_naiv = mms.fit_transform(dists.reshape(-1, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d610117",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_val = spearmanr(y_naiv, y_val)[0]\n",
    "pearson_val = pearsonr(y_naiv, y_val)[0]\n",
    "print(f\"SpearmanRank-val: {spearman_val:.4f}\")\n",
    "print(f\"PearsonRank-val: {pearson_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "spearman_val = spearmanr(y_pred, y_val)[0]\n",
    "pearson_val = pearsonr(y_pred, y_val)[0]\n",
    "print(f\"SpearmanRank-val: {spearman_val:.4f}\")\n",
    "print(f\"PearsonRank-val: {pearson_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db264611-0f48-4b8b-978c-9c1b637472c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocess\n",
    "\n",
    "df = test_data[[\"s1\", \"s2\"]].copy()\n",
    "df[\"s1_processed\"] = df.s1.apply(preprocess)\n",
    "df[\"s2_processed\"] = df.s2.apply(preprocess)\n",
    "df[\"y_true\"] = y_val\n",
    "df[\"y_pred\"] = y_pred\n",
    "df[\"y_naiv\"] = y_naiv\n",
    "df[[\"root\", \"nsubj\", \"dobj\"]] = [pd.Series(s) for s in syntax_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b681c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.y_true - df.y_pred).abs() > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c79e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ad\" in get_topic_probs.vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b52d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_syntax_deps(test_data.s1)[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71dd82-4907-44ff-a30e-6ec8ab295f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.y_true - df.y_pred) < 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e543c6b",
   "metadata": {},
   "source": [
    "### Naive cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_lg\", exclude=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25653d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"tok2vec\"] = df[[\"s1\", \"s2\"]].apply(lambda row: nlp(row.s1).similarity(nlp(row.s2)), axis=1)\n",
    "# print(f\"SpearmanRank-val: {spearmanr(df.tok2vec, df.y_true)[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = nlp(\"Blue and red plane in mid-air flight.\")\n",
    "# print(\"\\t\".join([token.dep_ for token in doc]))\n",
    "# print(\"\\t\".join([token.lemma_ for token in doc]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2031cad5f309ecce3c7725635a5b7ce703908d09c65dbfde6df395d8b1d2cb2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
