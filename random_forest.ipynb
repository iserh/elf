{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d936036",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae80a0-5b64-4fdc-a194-01b12a52297f",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5bba398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from utils import (CoreXProbsFactory, LDAProbs, SyntaxFactory, preprocess,\n",
    "                   tokenize)\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "model_dir = Path(\"/home/iailab36/iser/models\")\n",
    "\n",
    "SEED = 1337\n",
    "COREX_HIDDEN = 128\n",
    "VEC_FEAT = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3639de72-d37d-43a6-a3b9-b0dd80c8e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load benchmark dataset\n",
    "train_data = pd.read_feather(data_dir / \"stsbenchmark\" / \"sts-train.feather\")\n",
    "val_data = pd.read_feather(data_dir / \"stsbenchmark\" / \"sts-dev.feather\")\n",
    "test_data = pd.read_feather(data_dir / \"stsbenchmark\" / \"sts-test.feather\")\n",
    "\n",
    "train_data = pd.concat([train_data, val_data]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932b988-63fc-4b0d-9da6-7b1f28009044",
   "metadata": {},
   "source": [
    "## Pre-compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dd268a3-0bc4-4346-82c3-af4fc9786a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = []\n",
    "features_val = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d9631-bda1-404d-82b6-de3cea1ea494",
   "metadata": {},
   "source": [
    "### topic model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "593b88dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topic_probs = CoreXProbsFactory(\n",
    "    vectorizer_path=model_dir / f\"sts_vec={VEC_FEAT}\",\n",
    "    corex_name=f\"corex_n_hidden={COREX_HIDDEN}_iter=7\",\n",
    ")\n",
    "\n",
    "# get_topic_probs = LDAProbs(model_dir / f\"sts_lda_hidden={COREX_HIDDEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8023d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute topic probabilities\n",
    "topic_probs_train_1 = get_topic_probs(train_data.s1)\n",
    "topic_probs_train_2 = get_topic_probs(train_data.s2)\n",
    "topic_probs_test_1 = get_topic_probs(test_data.s1)\n",
    "topic_probs_test_2 = get_topic_probs(test_data.s2)\n",
    "# concatenate topics of the two sentences\n",
    "topic_probs_train = np.concatenate([topic_probs_train_1, topic_probs_train_2], axis=1)\n",
    "topic_probs_test = np.concatenate([topic_probs_test_1, topic_probs_test_2], axis=1)\n",
    "# add to features list\n",
    "features_train.append(topic_probs_train)\n",
    "features_val.append(topic_probs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5e1bd-6f65-416a-ae66-d30480beb0ac",
   "metadata": {},
   "source": [
    "### syntax features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ea3583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_syntax_deps = SyntaxFactory()\n",
    "# # compute syntax tokens\n",
    "# syntax_train_1 = get_syntax_deps(train_data.s1)\n",
    "# syntax_train_2 = get_syntax_deps(train_data.s2)\n",
    "# syntax_test_1 = get_syntax_deps(test_data.s1)\n",
    "# syntax_test_2 = get_syntax_deps(test_data.s2)\n",
    "# # mask matching syntax\n",
    "# syntax_train = (syntax_train_1 == syntax_train_2).astype(int)\n",
    "# syntax_test = (syntax_test_1 == syntax_test_2).astype(int)\n",
    "# # append to features list\n",
    "# features_train.append(syntax_train)\n",
    "# features_val.append(syntax_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb0237",
   "metadata": {},
   "source": [
    "## Training without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01c54bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (7030, 256)\n"
     ]
    }
   ],
   "source": [
    "# create input vectors\n",
    "X_train = np.concatenate(features_train, axis=1)\n",
    "X_test = np.concatenate(features_val, axis=1)\n",
    "# create targets\n",
    "y_train = train_data.score\n",
    "y_test = test_data.score\n",
    "print(\"X_train:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f11c5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = lambda SEED: RandomForestRegressor(criterion=\"squared_error\", n_estimators=100, random_state=SEED)\n",
    "decision_tree = lambda SEED: DecisionTreeRegressor(random_state=SEED, max_depth=5)\n",
    "mlp = lambda SEED: MLPRegressor((512, 256), random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "539bac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanRank-train: 0.3328,\t SpearmanRank-test: 0.1868\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "perm = np.random.permutation(X_train.shape[0])\n",
    "X_train_ = X_train[perm]\n",
    "y_train_ = y_train[perm]\n",
    "\n",
    "model = decision_tree(SEED)\n",
    "model.fit(X_train_, y_train_)\n",
    "\n",
    "# evaluate model\n",
    "spearman_train = spearmanr(model.predict(X_train), y_train)[0]\n",
    "spearman_test = spearmanr(model.predict(X_test), y_test)[0]\n",
    "\n",
    "print(f\"SpearmanRank-train: {spearman_train:.4f},\\t SpearmanRank-test: {spearman_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b30fd-3063-4941-9b5c-8ba14e948361",
   "metadata": {},
   "source": [
    "## Training with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4605f626-fdda-4253-81aa-e58530d6c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load augmentation dataset\n",
    "aug_data = pd.read_feather(data_dir / \"stsbenchmark\" / \"df_augment.feather\")\n",
    "\n",
    "features_aug = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc96d846",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_probs_train_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/iai/user/iser/dev/explainable-linguistic-features/random_forest.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Biailab32/home/iai/user/iser/dev/explainable-linguistic-features/random_forest.ipynb#ch0000017vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# get topics of the augmented sentences\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Biailab32/home/iai/user/iser/dev/explainable-linguistic-features/random_forest.ipynb#ch0000017vscode-remote?line=1'>2</a>\u001b[0m topic_probs_augmented \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Biailab32/home/iai/user/iser/dev/explainable-linguistic-features/random_forest.ipynb#ch0000017vscode-remote?line=2'>3</a>\u001b[0m     topic_probs_train_1[aug_data\u001b[39m.\u001b[39midx1],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Biailab32/home/iai/user/iser/dev/explainable-linguistic-features/random_forest.ipynb#ch0000017vscode-remote?line=3'>4</a>\u001b[0m     topic_probs_train_2[aug_data\u001b[39m.\u001b[39midx2]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Biailab32/home/iai/user/iser/dev/explainable-linguistic-features/random_forest.ipynb#ch0000017vscode-remote?line=4'>5</a>\u001b[0m ], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Biailab32/home/iai/user/iser/dev/explainable-linguistic-features/random_forest.ipynb#ch0000017vscode-remote?line=5'>6</a>\u001b[0m features_aug\u001b[39m.\u001b[39mappend(topic_probs_augmented)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topic_probs_train_1' is not defined"
     ]
    }
   ],
   "source": [
    "# get topics of the augmented sentences\n",
    "topic_probs_augmented = np.concatenate([\n",
    "    topic_probs_train_1[aug_data.idx1],\n",
    "    topic_probs_train_2[aug_data.idx2]\n",
    "], axis=1)\n",
    "features_aug.append(topic_probs_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "204a0b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # syntax features\n",
    "# syntax_aug = (syntax_train_1[aug_data.idx1] == syntax_train_2[aug_data.idx2]).astype(int)\n",
    "# features_aug.append(syntax_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f11a8e5-2a08-4886-9839-72c29bb8d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inputs / targets of augmented dataset\n",
    "X_aug = np.concatenate(features_aug, axis=1)\n",
    "y_aug = aug_data.score\n",
    "print(f\"#augmented: {y_aug.shape[0]}\")\n",
    "\n",
    "X_train_w_aug = np.concatenate([X_train, X_aug])\n",
    "y_train_w_aug = np.concatenate([y_train, y_aug])\n",
    "print(f\"#(train+augmented): {y_train_w_aug.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "perm = np.random.permutation(X_train_w_aug.shape[0])\n",
    "X_train_w_aug_ = X_train_w_aug[perm]\n",
    "y_train_w_aug_ = y_train_w_aug[perm]\n",
    "\n",
    "model = random_forest(SEED)\n",
    "model.fit(X_train_w_aug_, y_train_w_aug_)\n",
    "\n",
    "# evaluate model\n",
    "spearman_train = spearmanr(model.predict(X_train), y_train)[0]\n",
    "spearman_test = spearmanr(model.predict(X_test), y_test)[0]\n",
    "\n",
    "print(f\"SpearmanRank-train: {spearman_train:.4f},\\t SpearmanRank-test: {spearman_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a683639f",
   "metadata": {},
   "source": [
    "## Qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca992f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unit vectors\n",
    "# x1 = topic_probs_train_1 / np.linalg.norm(topic_probs_train_1, axis=1)[:, None]\n",
    "# x2 = topic_probs_train_2 / np.linalg.norm(topic_probs_train_2, axis=1)[:, None]\n",
    "\n",
    "# y_naiv = (x1[:, None, ...] @ x2[..., None]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import wasserstein_distance\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # softmax\n",
    "# x1 = np.exp(topic_probs_train_1)/np.exp(topic_probs_train_1).sum(0)\n",
    "# x2 = np.exp(topic_probs_train_2)/np.exp(topic_probs_train_2).sum(0)\n",
    "\n",
    "# dists = np.array([wasserstein_distance(x1[i], x2[i]) for i in range(x1.shape[0])])\n",
    "\n",
    "# mms = MinMaxScaler()\n",
    "# y_naiv = mms.fit_transform(dists.reshape(-1, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958fe9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "# vectorizer = CountVectorizer()\n",
    "vectorizer.fit(pd.concat([train_data.s1, train_data.s2]).apply(preprocess))\n",
    "bow1 = vectorizer.transform(test_data.s1.apply(preprocess)).toarray()\n",
    "bow2 = vectorizer.transform(test_data.s2.apply(preprocess)).toarray()\n",
    "\n",
    "bow1 = bow1 / np.linalg.norm(bow1, axis=1)[:, None]\n",
    "bow2 = bow2 / np.linalg.norm(bow2, axis=1)[:, None]\n",
    "\n",
    "y_naiv = (bow1[:, None, ...] @ bow2[..., None]).squeeze()\n",
    "\n",
    "spearman_val = spearmanr(y_naiv, y_test)[0]\n",
    "print(f\"Naive SpearmanRank-val: {spearman_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# load sbert model\n",
    "sbert = SentenceTransformer(\"stsb-mpnet-base-v2\")\n",
    "\n",
    "# compute sentence embeddings with sbert\n",
    "emb_1 = sbert.encode(test_data.s1, convert_to_tensor=True, device=device)\n",
    "emb_2 = sbert.encode(test_data.s2, convert_to_tensor=True, device=device)\n",
    "\n",
    "# compute similarity scores via cosine similarity\n",
    "emb_1 = F.normalize(emb_1)\n",
    "emb_2 = F.normalize(emb_2)\n",
    "y_pred_sbert = (emb_1.unsqueeze(1) @ emb_2.unsqueeze(2)).squeeze(1).cpu().numpy()\n",
    "# scale scores to [0, 1]\n",
    "y_pred_sbert = MinMaxScaler().fit_transform(y_pred_sbert).squeeze()\n",
    "\n",
    "spearman_val = spearmanr(y_pred_sbert, y_test)[0]\n",
    "print(f\"S-BERT SpearmanRank-val: {spearman_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42067029",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax[0].scatter(y_naiv, y_test)\n",
    "ax[0].set_title(\"Naive\")\n",
    "ax[1].scatter(y_pred_sbert, y_test)\n",
    "ax[1].set_title(\"S-BERT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "spearman_val = spearmanr(y_pred, y_test)[0]\n",
    "print(f\"Topic Modeling SpearmanRank-val: {spearman_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db264611-0f48-4b8b-978c-9c1b637472c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_data[[\"s1\", \"s2\"]].copy()\n",
    "df[\"s1_processed\"] = df.s1.apply(preprocess)\n",
    "df[\"s2_processed\"] = df.s2.apply(preprocess)\n",
    "df[\"y_true\"] = y_test\n",
    "df[\"y_pred\"] = y_pred\n",
    "df[\"y_naiv\"] = y_naiv\n",
    "# df[[\"root\", \"nsubj\", \"dobj\"]] = [pd.Series(s) for s in syntax_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b681c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.y_true - df.y_naiv).abs() > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c79e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"ad\" in get_topic_probs.vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e543c6b",
   "metadata": {},
   "source": [
    "### Naive cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_lg\", exclude=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25653d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"tok2vec\"] = df[[\"s1\", \"s2\"]].apply(lambda row: nlp(row.s1).similarity(nlp(row.s2)), axis=1)\n",
    "# print(f\"SpearmanRank-val: {spearmanr(df.tok2vec, df.y_true)[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = nlp(\"Blue and red plane in mid-air flight.\")\n",
    "# print(\"\\t\".join([token.dep_ for token in doc]))\n",
    "# print(\"\\t\".join([token.lemma_ for token in doc]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2031cad5f309ecce3c7725635a5b7ce703908d09c65dbfde6df395d8b1d2cb2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
